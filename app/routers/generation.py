from __future__ import annotations

import os
import html
import asyncio
from typing import Optional, Tuple, List

from aiogram import Router, F
from aiogram.types import (
    CallbackQuery,
    Message,
    InputMediaPhoto,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
)
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.exceptions import TelegramBadRequest

from sqlalchemy import select, insert, update

from app.keyboards import (
    prompt_editor_kb,
    image_actions_kb,
    gen_confirm_kb,
    models_kb,
    count_kb,
)
from app.db import async_session
from app.models import User, Generation, ApiCredentials, UserSettings
from app.services.ai_text import OpenAITextClient, DummyTextClient
from app.services.tensorart import (
    TensorArtClient,
    TensorArtError,
    build_txt2img_stages,
)
from app.crypto import fernet_decrypt
from app.config import settings

from pathlib import Path
from types import SimpleNamespace
import json

router = Router()

# ====== –ë–ê–ó–´ –¥–ª—è SD ======
SD_BASE = (
    "score_9, score_8_up, score_7_up, score_6_up, highly detailed, intricate, "
    "intricate details, highly detailed face, s1_dram, best quality, high resolution, "
    "4k, 8k, 16k, volumetric light, sharp focus, highly detailed, detalized eyes"
)

NEGATIVE_BASE = (
    "bad-artist, bad-hands-5, bad_quality, "
    "lowres, ugly, extra limbs, missing limbs, extra legs, missing legs, "
    "worst quality, low quality, bad hands, extra fingers, missing fingers"
)

# ====== –ö–û–ù–°–¢–ê–ù–¢–´ –ú–û–î–ï–õ–ï–ô –∏ LORA ======
MODELS: list[tuple[str, str]] = [
    ("714585990280309972", "PonyDiffusion"),
    ("860853672081403449", "WAI (ILL)"),
    ("892127662204519332", "Hassaku XL (ILL)"),
]
LORAS: list[tuple[str, str]] = [
    ("795508864968560995","748cm LoRA"),
    ("800080913489928401","MoriiMee Gothica Niji LoRA"),
    ("707483316963647220","Anime Enhancer XL"),
    ("832408453722028074","NAIXL Zoroj Style"),
    ("885831941302052058","NoobAI-XL Detailer"),
    ("832279127961775445","ma1ma1helmes | Style LoRa "),
    ("825592757235081468","Sinozick ExpressiveH"),
    ("876293834697364164","Incase + Vixon's Gothic Neon"),
]

DA_DISCLAIMER = (
    ") <b>This adopt is generated by AI Midjourney after buy, u got clear image without watermark "
    "Everyone can also order custom work-commission art:3 You can use anything you want if you buy it! üíñ "
    "Paypal accepted WHEN YOU BUY, NO RETURNS, you need to make sure you like it and there will be no problems in the future.</b>"
)

def _render_da_preview(title: str, description: str, hashtags: list[str]) -> str:
    tags_line = " ".join((hashtags or [])[:30])
    return (
        "<b>–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–ª—è DeviantArt</b>\n"
        f"<b>Title:</b> {html.escape(title)}\n\n"
        f"<b>Description:</b>\n{DA_DISCLAIMER}\n\n{html.escape(description)}\n\n"
        f"<b>Hashtags (30):</b>\n{html.escape(tags_line)}"
    )


def _loras_select_kb(selected: set[str]) -> InlineKeyboardMarkup:
    """
    –ò–Ω–ª–∞–π–Ω-–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∞ LoRA —Å –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–º–∏ –≥–∞–ª–æ—á–∫–∞–º–∏.
    selected ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ id —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö LoRA.
    """
    rows: list[list[InlineKeyboardButton]] = []
    for lid, name in LORAS:
        mark = "‚úÖ" if lid in selected else "‚¨ú"
        rows.append([InlineKeyboardButton(text=f"{mark} {name}", callback_data=f"lora:toggle:{lid}")])

    rows.append([
        InlineKeyboardButton(text="‚úÖ –ì–æ—Ç–æ–≤–æ", callback_data="lora:done"),
        InlineKeyboardButton(text="‚è≠ –ë–µ–∑ LoRA", callback_data="lora:skip"),
    ])
    rows.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –º–æ–¥–µ–ª—è–º", callback_data="model:open")])

    return InlineKeyboardMarkup(inline_keyboard=rows)

# ====== FSM ======
class EditorStates(StatesGroup):
    editing_main = State()
    editing_sd = State()
    editing_negative = State()

class IdeaStates(StatesGroup):
    waiting_text = State()

class PromptStates(StatesGroup):
    waiting_main_prompt = State()

# ---------- helpers: AI client ----------
def _get_ai_client():
    api_key = getattr(settings, "OPENAI_API_KEY", None) or os.getenv("OPENAI_API_KEY")
    base = getattr(settings, "OPENAI_API_BASE", None) or os.getenv("OPENAI_API_BASE")
    model = getattr(settings, "TEXT_MODEL", None) or os.getenv("TEXT_MODEL") or "gpt-5-nano"
    if api_key:
        return OpenAITextClient(api_key=api_key, base_url=base, model=model)
    return DummyTextClient()

# ---------- JSON storage for user settings (+ active_gen_id) ----------
SETTINGS_JSON = Path(__file__).resolve().parent.parent / "user_settings.json"

def _json_read_all() -> dict:
    try:
        if SETTINGS_JSON.exists():
            return json.loads(SETTINGS_JSON.read_text(encoding="utf-8"))
    except Exception:
        pass
    return {}

def _json_write_all(data: dict) -> None:
    try:
        SETTINGS_JSON.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception:
        # –≤ –ø—Ä–æ–¥–µ –º–æ–∂–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å
        pass

def _json_upsert(user_key: int, patch: dict):
    data = _json_read_all()
    key = str(user_key)
    cur = data.get(key) or {}
    cur.update(patch)
    data[key] = cur
    _json_write_all(data)

def _json_get_active_gen_id(user_key: int) -> Optional[int]:
    try:
        data = _json_read_all()
        node = data.get(str(user_key)) or {}
        v = node.get("active_gen_id")
        return int(v) if v is not None else None
    except Exception:
        return None

def _json_set_active_gen_id_for_both(tg_user_id: int | None, db_user_id: int | None, gen_id: int):
    if tg_user_id is not None:
        _json_upsert(tg_user_id, {"active_gen_id": gen_id})
    if db_user_id is not None:
        _json_upsert(db_user_id, {"active_gen_id": gen_id})

def _json_get_settings_by_key(key: int) -> Optional[SimpleNamespace]:
    try:
        data = _json_read_all()
        u = data.get(str(key))
        if u:
            return SimpleNamespace(
                width=int(u.get("width", 768)),
                height=int(u.get("height", 1152)),
                steps=min(int(u.get("steps", 20)), 20),
                cfg_scale=min(float(u.get("cfg_scale", 4.0)), 10.0),
                model_id=u.get("model_id"),
                sd_model_id=u.get("sd_model_id"),
                clip_skip=u.get("clip_skip"),
                active_gen_id=u.get("active_gen_id"),
            )
    except Exception:
        pass
    return None

# ---------- –ë–ê–ó–û–í–´–ï DAO ----------
async def get_user(tg_id: int, username: Optional[str]):
    async with async_session() as s:
        r = await s.execute(select(User).where(User.tg_id == tg_id))
        u = r.scalar_one_or_none()
        if not u:
            u = User(tg_id=tg_id, username=username)
            s.add(u)
            await s.commit()
            await s.refresh(u)
        return u

# ======= –¥–µ—Ñ–æ–ª—Ç—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è =======
ALLOWED_SIZES = {(768, 1152), (1024, 1024)}
DEFAULT_WIDTH = 768
DEFAULT_HEIGHT = 1152
DEFAULT_STEPS = 20
DEFAULT_CFG = 4.0

def _normalize_values(width: int, height: int, steps: int, cfg: float) -> tuple[int, int, int, float]:
    w, h = int(width or 0), int(height or 0)
    if (w, h) not in ALLOWED_SIZES:
        if w == 768:
            w, h = 768, 1152
        elif w == 1024:
            w, h = 1024, 1024
        else:
            w, h = DEFAULT_WIDTH, DEFAULT_HEIGHT
    s = max(1, min(int(steps or DEFAULT_STEPS), 20))
    c = max(1.0, min(float(cfg or DEFAULT_CFG), 10.0))
    return w, h, s, c

async def get_or_create_user_settings(user_id: int) -> UserSettings:
    async with async_session() as s:
        r = await s.execute(select(UserSettings).where(UserSettings.user_id == user_id))
        st = r.scalar_one_or_none()
        if not st:
            env_w = getattr(settings, "TENSORART_WIDTH", None)
            env_h = getattr(settings, "TENSORART_HEIGHT", None)
            env_steps = getattr(settings, "TENSORART_STEPS", None)
            env_cfg = getattr(settings, "TENSORART_CFG", None)
            w = int(env_w) if env_w is not None else DEFAULT_WIDTH
            h = int(env_h) if env_h is not None else DEFAULT_HEIGHT
            stp = int(env_steps) if env_steps is not None else DEFAULT_STEPS
            cfg = float(env_cfg) if env_cfg is not None else DEFAULT_CFG
            w, h, stp, cfg = _normalize_values(w, h, stp, cfg)
            st = UserSettings(
                user_id=user_id,
                width=w,
                height=h,
                steps=stp,
                cfg_scale=cfg,
                model_id=getattr(settings, "TENSORART_MODEL_ID", None),
            )
            s.add(st)
            await s.commit()
            await s.refresh(st)
            return st

        w2, h2, stp2, cfg2 = _normalize_values(st.width, st.height, st.steps, float(st.cfg_scale))
        if (st.width, st.height, st.steps, float(st.cfg_scale)) != (w2, h2, stp2, cfg2):
            st.width = w2
            st.height = h2
            st.steps = stp2
            st.cfg_scale = cfg2
            s.add(st)
            await s.commit()
            await s.refresh(st)
        return st

async def set_current_gen(state: FSMContext, gen_id: int):
    data = await state.get_data()
    data["current_gen_id"] = gen_id
    await state.set_data(data)

async def get_current_gen_id(state: FSMContext, user_key: int) -> Optional[int]:
    """user_key –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫ DB user_id, —Ç–∞–∫ –∏ tg_id.
    –ü–æ—Ä—è–¥–æ–∫: FSM -> JSON(active_gen_id) -> –ë–î(–ø–æ—Å–ª–µ–¥–Ω—è—è)."""
    # 1) FSM
    data = await state.get_data()
    gen_id = data.get("current_gen_id")
    if gen_id:
        return gen_id

    # 2) JSON –ø–æ –¥–∞–Ω–Ω–æ–º—É –∫–ª—é—á—É
    gen_id = _json_get_active_gen_id(user_key)
    if gen_id:
        return gen_id

    # 3) –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω tg_id ‚Äî –Ω–∞–π–¥—ë–º db id –∏ –ø—Ä–æ–≤–µ—Ä–∏–º JSON —Ç–∞–º
    async with async_session() as s:
        r2 = await s.execute(select(User.id).where(User.tg_id == user_key))
        db_id = r2.scalar_one_or_none()
        if db_id:
            gen_id = _json_get_active_gen_id(db_id)
            if gen_id:
                return gen_id

        # 4) –ü–æ—Å–ª–µ–¥–Ω—è—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ –ë–î (fallback)
        base_id = db_id or user_key
        r = await s.execute(
            select(Generation.id)
            .where(Generation.user_id == base_id)
            .order_by(Generation.id.desc())
        )
        row = r.first()
        return row[0] if row else None

async def get_user_settings_any(db_user_id: int, tg_user_id: Optional[int] = None) -> SimpleNamespace:
    if tg_user_id is not None:
        js = _json_get_settings_by_key(tg_user_id)
        if js:
            return js
    js2 = _json_get_settings_by_key(db_user_id)
    if js2:
        return js2
    try:
        st = await get_or_create_user_settings(db_user_id)
        return SimpleNamespace(
            width=int(getattr(st, "width", 768)),
            height=int(getattr(st, "height", 1152)),
            steps=min(int(getattr(st, "steps", 20)), 20),
            cfg_scale=min(float(getattr(st, "cfg_scale", 4.0)), 10.0),
            model_id=getattr(st, "model_id", None),
            sd_model_id=getattr(st, "sd_model_id", None),
            clip_skip=getattr(st, "clip_skip", None),
        )
    except Exception:
        return SimpleNamespace(width=768, height=1152, steps=20, cfg_scale=4.0)

# ---------- –†–µ–Ω–¥–µ—Ä—ã ----------
def render_text_block_simple(gen: Generation, *, llm_model: Optional[str] = None) -> str:
    main_prompt = (gen.description or "").strip()
    llm_line = f"\n<b>LLM –º–æ–¥–µ–ª—å:</b> {html.escape(llm_model)}" if llm_model else ""
    return (
        f"<b>{gen.title or 'Custom generation'}</b>\n\n"
        f"<b>–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç (–ø–æ —à–∞–±–ª–æ–Ω—É):</b>\n<code>{html.escape(main_prompt)}</code>\n\n"
        f"<b>SD Prompt</b> <i>(–¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –ö–û–ù–ï–¶ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞; –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)</i>:\n"
        f"<code>{html.escape(gen.prompt or '')}</code>\n\n"
        f"<b>Negative:</b>\n<code>{html.escape(gen.negative_prompt or '')}</code>"
        f"{llm_line}"
    )


# ---------- utility: ensure generation ----------
async def _ensure_generation_for_user(db_user_id: int, *, tg_user_id: int | None = None) -> int:
    """–°–æ–∑–¥–∞—ë—Ç —á–µ—Ä–Ω–æ–≤–∏–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ—ë id –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç –µ–≥–æ –≤ JSON –∫–∞–∫ active_gen_id."""
    async with async_session() as s:
        q = await s.execute(
            insert(Generation)
            .values(
                user_id=db_user_id,
                title="Custom generation",
                description="",
                tags_csv="",
                prompt=SD_BASE,
                negative_prompt=NEGATIVE_BASE,
                style="custom",
                status="text_ready",
                image_cost_credits=0.0,
            )
            .returning(Generation.id)
        )
        gen_id = q.scalar_one()
        await s.commit()

    # persist pointer in JSON for both keys (tg –∏ db)
    _json_set_active_gen_id_for_both(tg_user_id, db_user_id, gen_id)
    return gen_id

# ---------- –°—Ç–∞—Ä—Ç ----------
@router.callback_query(F.data == "gen:new")
async def choose_model_start(cb: CallbackQuery, state: FSMContext):
    await state.update_data(
        selected_model_id=None,
        selected_model_name=None,
        selected_loras=[],
        loras_ready=False,
        image_count=1,
    )
    await cb.message.answer("–®–∞–≥ 1/4. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º–æ–¥–µ–ª—å</b>:", reply_markup=models_kb(MODELS, None))
    await cb.answer()

@router.callback_query(F.data == "back:styles")
async def back_styles(cb: CallbackQuery):
    await cb.message.edit_text("–®–∞–≥ 1/4. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º–æ–¥–µ–ª—å</b>:", reply_markup=models_kb(MODELS, None))
    await cb.answer()

# ---------- –†–µ–¥–∞–∫—Ç–æ—Ä: –ø—Ä–∞–≤–∫–∞ –û–°–ù–û–í–ù–û–ì–û / SD / NEGATIVE ----------
@router.callback_query(F.data == "editor:edit_main")
async def editor_edit_main(cb: CallbackQuery, state: FSMContext):
    u = await get_user(cb.from_user.id, cb.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=cb.from_user.id)
        await set_current_gen(state, gen_id)
    await state.set_state(EditorStates.editing_main)
    await cb.message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è <b>–û—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞</b> (–∑–∞–º–µ–Ω–∏—Ç —Ç–µ–∫—É—â–∏–π).", parse_mode="HTML")
    await cb.answer()

@router.message(EditorStates.editing_main)
async def save_new_main_prompt(msg: Message, state: FSMContext):
    u = await get_user(msg.from_user.id, msg.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=msg.from_user.id)
        await set_current_gen(state, gen_id)

    new_main = (msg.text or "").strip()
    async with async_session() as s:
        await s.execute(update(Generation).where(Generation.id == gen_id).values(description=new_main))
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()
        await s.commit()

    _json_set_active_gen_id_for_both(msg.from_user.id, u.id, gen_id)
    await msg.answer("–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç –æ–±–Ω–æ–≤–ª—ë–Ω ‚úÖ")
    await msg.answer(render_text_block_simple(gen), reply_markup=prompt_editor_kb(gen_id))
    await state.set_state(None)

@router.callback_query(F.data == "editor:edit_sd")
@router.callback_query(F.data == "editor:edit")  # –∞–ª–∏–∞—Å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async def editor_edit_sd(cb: CallbackQuery, state: FSMContext):
    u = await get_user(cb.from_user.id, cb.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=cb.from_user.id)
        await set_current_gen(state, gen_id)
    await state.set_state(EditorStates.editing_sd)
    await cb.message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–≤—ã–π <b>SD-–ø—Ä–æ–º–ø—Ç</b> (–∑–∞–º–µ–Ω–∏—Ç —Ç–µ–∫—É—â–∏–π).", parse_mode="HTML")
    await cb.answer()

@router.message(EditorStates.editing_sd)
async def save_new_sd_prompt(msg: Message, state: FSMContext):
    u = await get_user(msg.from_user.id, msg.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=msg.from_user.id)
        await set_current_gen(state, gen_id)

    new_prompt = (msg.text or "").strip()
    async with async_session() as s:
        await s.execute(update(Generation).where(Generation.id == gen_id).values(prompt=new_prompt))
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()
        await s.commit()

    _json_set_active_gen_id_for_both(msg.from_user.id, u.id, gen_id)
    await msg.answer("SD-–ø—Ä–æ–º–ø—Ç –æ–±–Ω–æ–≤–ª—ë–Ω ‚úÖ")
    await msg.answer(render_text_block_simple(gen), reply_markup=prompt_editor_kb(gen_id))
    await state.set_state(None)

@router.callback_query(F.data == "editor:edit_negative")
async def editor_edit_negative(cb: CallbackQuery, state: FSMContext):
    u = await get_user(cb.from_user.id, cb.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=cb.from_user.id)
        await set_current_gen(state, gen_id)
    await state.set_state(EditorStates.editing_negative)
    await cb.message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è <b>Negative</b> (–∑–∞–º–µ–Ω–∏—Ç —Ç–µ–∫—É—â–∏–π).", parse_mode="HTML")
    await cb.answer()

@router.message(EditorStates.editing_negative)
async def save_new_negative(msg: Message, state: FSMContext):
    u = await get_user(msg.from_user.id, msg.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=msg.from_user.id)
        await set_current_gen(state, gen_id)

    new_neg = (msg.text or "").strip()
    async with async_session() as s:
        await s.execute(update(Generation).where(Generation.id == gen_id).values(negative_prompt=new_neg))
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()
        await s.commit()

    _json_set_active_gen_id_for_both(msg.from_user.id, u.id, gen_id)
    await msg.answer("Negative –æ–±–Ω–æ–≤–ª—ë–Ω ‚úÖ")
    await msg.answer(render_text_block_simple(gen), reply_markup=prompt_editor_kb(gen_id))
    await state.set_state(None)

# ---------- –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ ----------
def _local_credits_estimate(width: int, height: int, steps: int, lora_count: int) -> float:
    mp = (width * height) / 1_000_000
    per_mp_step = getattr(settings, "CREDITS_PER_MP_STEP", 0.02)
    lora_factor = 1.0 + 0.05 * lora_count
    return mp * steps * per_mp_step * lora_factor

@router.callback_query(F.data == "img:estimate")
async def img_estimate(cb: CallbackQuery, state: FSMContext):
    try:
        u = await get_user(cb.from_user.id, cb.from_user.username)
        gen_id = await get_current_gen_id(state, u.id)
        if not gen_id:
            gen_id = await _ensure_generation_for_user(u.id, tg_user_id=cb.from_user.id)
            await set_current_gen(state, gen_id)

        st = await get_user_settings_any(db_user_id=u.id, tg_user_id=cb.from_user.id)
        data = await state.get_data()
        sel_loras: list[dict] = data.get("selected_loras") or []
        sel_count: int = int(data.get("image_count") or 1)

        loras_count = len(sel_loras)
        credits = _local_credits_estimate(st.width, st.height, st.steps, loras_count) * max(1, sel_count)

        await cb.message.answer(
            (
                f"–ß–µ—Ä–Ω–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: ~{credits:.2f} –∫—Ä–µ–¥–∏—Ç–æ–≤\n"
                f"{st.width}√ó{st.height}px, steps={st.steps}, cfg={st.cfg_scale}"
            ),
            parse_mode=None,
            reply_markup=gen_confirm_kb(gen_id, credits),
        )
        await cb.answer()
    except Exception as e:
        await cb.message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å: {html.escape(str(e))}", parse_mode=None)
        await cb.answer()

# ---------- –ú–æ–¥–µ–ª—å / LoRA / –ö–æ–ª-–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ----------
@router.callback_query(F.data.startswith("model:pick:"))
async def pick_model(cb: CallbackQuery, state: FSMContext):
    model_id = cb.data.split(":")[-1]
    name = next((n for mid, n in MODELS if mid == model_id), None)
    if not name:
        await cb.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å", show_alert=True)
        return
    await state.update_data(
        selected_model_id=model_id,
        selected_model_name=name,
        selected_loras=[],
        loras_ready=False,
    )
    await cb.message.edit_text("–®–∞–≥ 1/4. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º–æ–¥–µ–ª—å</b>:", reply_markup=models_kb(MODELS, model_id))
    await lora_open(cb, state)
    await cb.answer("–ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞")

@router.callback_query(F.data == "model:open")
async def model_open(cb: CallbackQuery, state: FSMContext):
    data = await state.get_data()
    sel = data.get("selected_model_id")
    await cb.message.edit_text("–®–∞–≥ 1/4. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º–æ–¥–µ–ª—å</b>:", reply_markup=models_kb(MODELS, sel))
    await cb.answer()

@router.callback_query(F.data == "lora:open")
async def lora_open(cb: CallbackQuery, state: FSMContext):
    data = await state.get_data()
    if not data.get("selected_model_id"):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", show_alert=True)
        return
    selected = {x["id"] for x in (data.get("selected_loras") or [])}
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π –≤—ã–±–æ—Ä–∞ LoRA
    await cb.message.answer(
        "–®–∞–≥ 2/4. –í—ã–±–µ—Ä–∏—Ç–µ –¥–æ <b>4 LoRA</b> (–∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ë–µ–∑ LoRA¬ª), –∑–∞—Ç–µ–º ¬´–ì–æ—Ç–æ–≤–æ¬ª:",
        parse_mode="HTML",
        reply_markup=_loras_select_kb(selected),
    )
    await cb.answer()

@router.callback_query(F.data.startswith("lora:toggle:"))
async def lora_toggle(cb: CallbackQuery, state: FSMContext):
    lid = cb.data.split(":")[-1]
    if not any(lid == x for x, _ in LORAS):
        await cb.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è LoRA", show_alert=True)
        return

    data = await state.get_data()
    current: list[dict] = data.get("selected_loras") or []
    sel = {x["id"] for x in current}

    if lid in sel:
        current = [x for x in current if x["id"] != lid]
    else:
        if len(current) >= 4:
            await cb.answer("–ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ –±–æ–ª—å—à–µ 4", show_alert=True)
            return
        name = next(n for x, n in LORAS if x == lid)
        current.append({"id": lid, "name": name, "weight": 0.8})

    await state.update_data(selected_loras=current, loras_ready=False)

    # üîß –ú–ì–ù–û–í–ï–ù–ù–û –æ–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    new_sel = {x["id"] for x in current}
    try:
        await cb.message.edit_reply_markup(reply_markup=_loras_select_kb(new_sel))
    except Exception:
        # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ–ª—å–∑—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å (—É–¥–∞–ª–µ–Ω–æ/–∏–∑–º–µ–Ω–µ–Ω–æ), –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
        pass

    await cb.answer()

@router.callback_query(F.data == "lora:done")
async def lora_done(cb: CallbackQuery, state: FSMContext):
    data = await state.get_data()
    if not data.get("selected_model_id"):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", show_alert=True)
        return
    await state.update_data(loras_ready=True)
    await idea_open(cb, state)
    await cb.answer("LoRA –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã")

@router.callback_query(F.data == "lora:skip")
async def lora_skip(cb: CallbackQuery, state: FSMContext):
    data = await state.get_data()
    if not data.get("selected_model_id"):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", show_alert=True)
        return
    await state.update_data(selected_loras=[], loras_ready=True)
    await idea_open(cb, state)
    await cb.answer("–ë–µ–∑ LoRA")

# ---------- –ò–¥–µ—è/–ø—Ä–æ–º–ø—Ç ----------
def _idea_choice_kb() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –∏–¥–µ—é", callback_data="idea:manual")],
        [InlineKeyboardButton(text="üìù –í–≤–µ—Å—Ç–∏ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç", callback_data="prompt:manual")],
        [InlineKeyboardButton(text="üé≤ –°–ª—É—á–∞–π–Ω–∞—è –∏–¥–µ—è", callback_data="idea:random")],
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ LoRA", callback_data="lora:open")],
    ])

@router.callback_query(F.data == "idea:open")
async def idea_open(cb: CallbackQuery, state: FSMContext):
    data = await state.get_data()
    if not data.get("selected_model_id"):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", show_alert=True)
        return
    if not data.get("loras_ready"):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ LoRA (–∏–ª–∏ ¬´–ë–µ–∑ LoRA¬ª) –∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ ¬´–ì–æ—Ç–æ–≤–æ¬ª.", show_alert=True)
        return

    await cb.message.answer(
        "–®–∞–≥ 3/4. –ö–∞–∫ –∑–∞–¥–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç?\n"
        "‚Ä¢ ‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –∏–¥–µ—é (—É–∫–∞–∂–∏—Ç–µ –º–∏–Ω–∏–º—É–º —Å—Ç–∏–ª—å, –≤–æ–∑—Ä–∞—Å—Ç, –≤–æ–ª–æ—Å—ã, —Ç.–ø) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LLM\n"
        "‚Ä¢ üìù –í–≤–µ—Å—Ç–∏ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç ‚Äî –±–µ–∑ LLM, –±–µ—Ä—ë–º –∫–∞–∫ –µ—Å—Ç—å\n"
        "‚Ä¢ üé≤ –°–ª—É—á–∞–π–Ω–∞—è –∏–¥–µ—è ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LLM",
        reply_markup=_idea_choice_kb(),
    )
    await cb.answer()

# --- –í–≤–µ—Å—Ç–∏ –∏–¥–µ—é (LLM) ---
@router.callback_query(F.data == "idea:manual")
async def idea_manual(cb: CallbackQuery, state: FSMContext):
    await state.set_state(IdeaStates.waiting_text)
    await cb.message.answer("–£–∫–∞–∂–∏—Ç–µ –º–∏–Ω–∏–º—É–º: —Å—Ç–∏–ª—å, –≤–æ–∑—Ä–∞—Å—Ç, –≤–æ–ª–æ—Å—ã, —Ç.–ø. –ï—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ ¬´-¬ª, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é —Å–ª—É—á–∞–π–Ω—ã–π.")
    await cb.answer()

@router.message(IdeaStates.waiting_text)
async def idea_manual_text(msg: Message, state: FSMContext):
    idea = (msg.text or "").strip()
    u = await get_user(msg.from_user.id, msg.from_user.username)

    data = await state.get_data()
    if not data.get("selected_model_id") or not data.get("loras_ready"):
        await msg.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≤–µ—Ä—à–∏—Ç–µ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ LoRA.")
        return

    ai = _get_ai_client()
    try:
        if idea in {"-", "‚Äî", "_"}:
            core = await ai.random_prompt(max_words=25)
        else:
            core = await ai.refine_from_idea(idea, max_words=20)
        model_used = getattr(ai, "last_model_used", None)
    except Exception as e:
        await msg.answer(f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–¥–µ—é: {html.escape(str(e))}\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        return
    finally:
        try:
            await ai.aclose()
        except Exception:
            pass

    sd_prompt = f"{SD_BASE}".strip().rstrip(",")
    negative = NEGATIVE_BASE
    main_prompt = core

    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=msg.from_user.id)
        await set_current_gen(state, gen_id)

    async with async_session() as s:
        await s.execute(update(Generation).where(Generation.id == gen_id).values(
            prompt=sd_prompt,
            negative_prompt=negative,
            description=main_prompt,
            title="Custom generation",
            status="text_ready",
            tags_csv=f"llm:{model_used or 'unknown'}"
        ))
        await s.commit()
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()

    _json_set_active_gen_id_for_both(msg.from_user.id, u.id, gen_id)
    await msg.answer("–ò–¥–µ—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ ‚úÖ")
    await msg.answer(render_text_block_simple(gen, llm_model=model_used), reply_markup=prompt_editor_kb(gen_id))
    await state.set_state(None)

# --- –í–≤–µ—Å—Ç–∏ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç (–±–µ–∑ LLM) ---
@router.callback_query(F.data == "prompt:manual")
async def prompt_manual(cb: CallbackQuery, state: FSMContext):
    await state.set_state(PromptStates.waiting_main_prompt)
    await cb.message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ <b>–ø–æ–ª–Ω—ã–π –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç</b>. –û–Ω –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–∞–∫ –µ—Å—Ç—å, –±–µ–∑ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ LLM.", parse_mode="HTML")
    await cb.answer()

@router.message(PromptStates.waiting_main_prompt)
async def prompt_manual_text(msg: Message, state: FSMContext):
    main_prompt = (msg.text or "").strip()
    if not main_prompt:
        await msg.answer("–ü—Ä–æ–º–ø—Ç –ø—É—Å—Ç–æ–π. –ü—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç.")
        return

    u = await get_user(msg.from_user.id, msg.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=msg.from_user.id)
        await set_current_gen(state, gen_id)

    sd_prompt = f"{SD_BASE}".strip().rstrip(",")
    negative = NEGATIVE_BASE

    async with async_session() as s:
        await s.execute(update(Generation).where(Generation.id == gen_id).values(
            prompt=sd_prompt,
            negative_prompt=negative,
            description=main_prompt,
            title="Custom generation",
            status="text_ready",
            tags_csv="manual:true"
        ))
        await s.commit()
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()

    _json_set_active_gen_id_for_both(msg.from_user.id, u.id, gen_id)
    await msg.answer("–ü—Ä–æ–º–ø—Ç –ø—Ä–∏–Ω—è—Ç ‚úÖ")
    await msg.answer(render_text_block_simple(gen), reply_markup=prompt_editor_kb(gen_id))
    await state.set_state(None)

# --- –°–ª—É—á–∞–π–Ω–∞—è –∏–¥–µ—è (LLM) ---
@router.callback_query(F.data == "idea:random")
async def idea_random(cb: CallbackQuery, state: FSMContext):
    u = await get_user(cb.from_user.id, cb.from_user.username)
    data = await state.get_data()
    if not data.get("selected_model_id") or not data.get("loras_ready"):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≤–µ—Ä—à–∏—Ç–µ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ LoRA.", show_alert=True)
        return

    ai = _get_ai_client()
    try:
        core = await ai.random_prompt(max_words=25)
        model_used = getattr(ai, "last_model_used", None)
    except Exception as e:
        await cb.message.answer(f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–¥–µ—é: {html.escape(str(e))}")
        await cb.answer()
        return
    finally:
        try:
            await ai.aclose()
        except Exception:
            pass

    sd_prompt = f"{SD_BASE}".strip().rstrip(",")
    negative = NEGATIVE_BASE
    main_prompt = core

    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=cb.from_user.id)
        await set_current_gen(state, gen_id)

    async with async_session() as s:
        await s.execute(update(Generation).where(Generation.id == gen_id).values(
            prompt=sd_prompt,
            negative_prompt=negative,
            description=main_prompt,
            title="Custom generation",
            status="text_ready",
            tags_csv=f"llm:{model_used or 'unknown'}"
        ))
        await s.commit()
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()

    _json_set_active_gen_id_for_both(cb.from_user.id, u.id, gen_id)
    await cb.message.answer("–°–ª—É—á–∞–π–Ω–∞—è –∏–¥–µ—è –≥–æ—Ç–æ–≤–∞ ‚úÖ")
    await cb.message.answer(render_text_block_simple(gen, llm_model=model_used), reply_markup=prompt_editor_kb(gen_id))
    await cb.answer()

# ---------- –ö–æ–ª-–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ----------
@router.callback_query(F.data == "count:open")
async def count_open(cb: CallbackQuery, state: FSMContext):
    u = await get_user(cb.from_user.id, cb.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏—Ç–µ –∏–¥–µ—é/–ø—Ä–æ–º–ø—Ç.", show_alert=True)
        return
    async with async_session() as s:
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()
    if not (gen.description and gen.description.strip()):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç: ¬´–≤–≤–µ—Å—Ç–∏ –∏–¥–µ—é¬ª, ¬´—Å–ª—É—á–∞–π–Ω–∞—è¬ª –∏–ª–∏ ¬´–≤–≤–µ—Å—Ç–∏ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç¬ª.", show_alert=True)
        return

    await cb.message.edit_text("–®–∞–≥ 4/4. –°–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å?", reply_markup=count_kb())
    await cb.answer()

@router.callback_query(F.data.startswith("count:pick:"))
async def count_pick(cb: CallbackQuery, state: FSMContext):
    n = int(cb.data.split(":")[-1])
    if n < 1 or n > 4:
        await cb.answer("–ú–æ–∂–Ω–æ 1‚Äì4", show_alert=True)
        return

    u = await get_user(cb.from_user.id, cb.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏—Ç–µ –∏–¥–µ—é/–ø—Ä–æ–º–ø—Ç.", show_alert=True)
        return
    async with async_session() as s:
        r = await s.execute(select(Generation).where(Generation.id == gen_id))
        gen = r.scalar_one()
    if not (gen.description and gen.description.strip()):
        await cb.answer("–°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç: ¬´–≤–≤–µ—Å—Ç–∏ –∏–¥–µ—é¬ª, ¬´—Å–ª—É—á–∞–π–Ω–∞—è¬ª –∏–ª–∏ ¬´–≤–≤–µ—Å—Ç–∏ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç¬ª.", show_alert=True)
        return

    await state.update_data(image_count=n)

    st = await get_user_settings_any(db_user_id=u.id, tg_user_id=cb.from_user.id)
    data = await state.get_data()
    model_name = data.get("selected_model_name") or "‚Äî"
    sel_loras: list[dict] = data.get("selected_loras") or []
    loras_names = ", ".join(x["name"] for x in sel_loras) if sel_loras else "‚Äî"

    credits = _local_credits_estimate(st.width, st.height, st.steps, len(sel_loras)) * n

    preview = (
        "<b>–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞</b>\n"
        f"–ú–æ–¥–µ–ª—å: <code>{model_name}</code>\n"
        f"LoRA: <code>{loras_names}</code>\n"
        f"–†–∞–∑–º–µ—Ä: <code>{st.width}√ó{st.height}</code>\n"
        f"Steps: <code>{st.steps}</code>\n"
        f"CFG: <code>{st.cfg_scale}</code>\n"
        f"–ö–∞–¥—Ä–æ–≤: <code>{n}</code>\n\n"
        f"–ß–µ—Ä–Ω–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: ~{credits:.2f} –∫—Ä–µ–¥–∏—Ç–æ–≤"
    )
    await cb.message.edit_text(preview, reply_markup=gen_confirm_kb(gen_id, credits))
    await cb.answer()

# ---------- Tensor.Art ----------
def _tensorart_client_from_creds(cred: ApiCredentials) -> TensorArtClient:
    token = fernet_decrypt(cred.access_token_enc)
    endpoint = getattr(settings, "TENSORART_REGION_URL", None) or getattr(settings, "TENSORART_ENDPOINT", None)
    app_id = getattr(settings, "TENSORART_APP_ID", None)
    if cred.meta_json and isinstance(cred.meta_json, dict):
        app_id = cred.meta_json.get("app_id") or app_id
    return TensorArtClient(api_key=token, region_url=endpoint, app_id=app_id)

def _extract_progress(snapshot: dict) -> Optional[int]:
    job = snapshot.get("job") or {}
    for key in ("progress", "percent", "progressPercent", "progress_percent"):
        v = job.get(key) or snapshot.get(key) or job.get("runningInfo", {}).get(key)
        try:
            if v is None:
                continue
            p = int(float(v))
            return max(0, min(100, p))
        except Exception:
            continue
    return None

# ---------- –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ----------
@router.callback_query(F.data.startswith("img:run"))
async def img_run(cb: CallbackQuery, state: FSMContext):
    parts = cb.data.split(":")
    gen_id = int(parts[2])

    u = await get_user(cb.from_user.id, cb.from_user.username)

    async with async_session() as s:
        r = await s.execute(
            select(Generation).where(Generation.id == gen_id, Generation.user_id == u.id)
        )
        gen = r.scalar_one()

    if not (gen.prompt and gen.prompt.strip()):
        await cb.message.answer("–°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏ –∏–¥–µ—é –ø—Ä–æ–º–ø—Ç–∞ (—à–∞–≥ 3/4).")
        await cb.answer()
        return

    async with async_session() as s:
        r = await s.execute(
            select(ApiCredentials).where(
                ApiCredentials.user_id == u.id, ApiCredentials.service == "tensorart"
            )
        )
        ta = r.scalar_one_or_none()

    if not ta:
        await cb.message.answer("–ù–µ—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω–æ–≥–æ Tensor.Art. –î–æ–±–∞–≤—å—Ç–µ –≤ –ø—Ä–æ—Ñ–∏–ª—å.")
        await cb.answer()
        return

    st = await get_user_settings_any(db_user_id=u.id, tg_user_id=cb.from_user.id)
    data = await state.get_data()
    selected_model_id: Optional[str] = data.get("selected_model_id") or None
    selected_loras: list[dict] = data.get("selected_loras") or []
    image_count: int = int(data.get("image_count") or 1)
    desired = max(1, min(image_count, 4))

    sd_model = selected_model_id or getattr(st, "sd_model_id", None) or getattr(st, "model_id", None) or getattr(
        settings, "TENSORART_SD_MODEL_ID", None
    )
    loras: List[Tuple[str, float]] = [(x["id"], float(x.get("weight") or 0.8)) for x in selected_loras][:4]

    client = _tensorart_client_from_creds(ta)

    try:
        stages = build_txt2img_stages(
            prompt=(gen.description or ""),         # –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç (–æ—Ç –∏–¥–µ–∏/LLM)
            sd_tail=SD_BASE,                        # –±–∞–∑–∞ –¥–ª—è SD (–¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –∫–æ–Ω–µ—Ü)
            negative=gen.negative_prompt or None,
            width=st.width,
            height=st.height,
            steps=st.steps,
            cfg_scale=st.cfg_scale,
            clip_skip=getattr(st, "clip_skip", None),
            sd_model=sd_model,
            loras=loras or None,
            count=desired,
        )

        job_id = await client.create_job(stages)
    except TensorArtError as e:
        await cb.message.answer(f"–û—à–∏–±–∫–∞ Tensor.Art: {html.escape(str(e))}", parse_mode=None)
        await cb.answer()
        await client.aclose()
        return
    except Exception as e:
        await cb.message.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ: {html.escape(repr(e))}", parse_mode=None)
        await cb.answer()
        await client.aclose()
        return

    progress_msg = await cb.message.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è‚Ä¶ 0%")

    urls: List[str] = []
    try:
        ready = {"succeeded", "completed", "done", "success", "finished"}
        running = {"queued", "pending", "processing", "running", "waiting"}
        while True:
            snap = await client.get_job(job_id)
            job = snap.get("job") or {}
            status = (job.get("status") or snap.get("status") or "").lower()

            pr = _extract_progress(snap)
            try:
                if pr is not None:
                    await progress_msg.edit_text(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è‚Ä¶ {pr}%")
            except TelegramBadRequest:
                pass

            if status in ready:
                # –ü–µ—Ä–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ —Å—Å—ã–ª–æ–∫
                urls = list(dict.fromkeys(await client.get_result_urls(job_id) or []))
                break
            if status in running or not status:
                await asyncio.sleep(2.0)
                continue
            await asyncio.sleep(2.0)

        # –î–æ–ø. –æ–ø—Ä–æ—Å ‚Äî –ø–æ–∫–∞ –Ω–µ —Å–æ–±–µ—Ä—ë–º –≤—Å–µ desired —Å—Å—ã–ª–∫–∏ (–∏–ª–∏ –Ω–µ –≤—ã–π–¥–µ–º –ø–æ —Ç–∞–π–º-–∞—É—Ç—É)
        deadline = asyncio.get_event_loop().time() + 120.0  # –µ—â—ë –¥–æ 120—Å –Ω–∞ –¥–æ–±–æ—Ä
        while len(urls) < desired and asyncio.get_event_loop().time() < deadline:
            await asyncio.sleep(2.0)
            more = await client.get_result_urls(job_id) or []
            # –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞
            merged = list(dict.fromkeys(urls + more))
            if len(merged) > len(urls):
                urls = merged

        if not urls:
            # –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –±–ª–æ–∫–∏—Ä—É—é—â–∏–π —Ñ–æ–ª–ª–±—ç–∫
            urls = await client.wait_result_urls(job_id, poll_interval=2.0, timeout=180.0)

    except Exception as e:
        try:
            await progress_msg.edit_text(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {html.escape(str(e))}")
        except TelegramBadRequest:
            await cb.message.answer(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {html.escape(str(e))}")
        await client.aclose()
        await cb.answer()
        return
    finally:
        await client.aclose()

    main_url = urls[0] if urls else None
    async with async_session() as s:
        await s.execute(
            update(Generation)
            .where(Generation.id == gen_id)
            .values(
                image_url=main_url,
                status="img_ready",
            )
        )
        await s.commit()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï –∫–∞–¥—Ä—ã –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    try:
        data_js = {}
        if SETTINGS_JSON.exists():
            data_js = json.loads(SETTINGS_JSON.read_text(encoding="utf-8") or "{}")
        key = str(cb.from_user.id)
        obj = data_js.get(key) or {}
        obj["last_image_urls"] = list(urls or ([] if not main_url else [main_url]))[:4]
        data_js[key] = obj
        SETTINGS_JSON.write_text(json.dumps(data_js, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception:
        pass

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    try:
        if len(urls) > 1:
            media = []
            for idx, uurl in enumerate(urls):
                if idx == 0:
                    media.append(InputMediaPhoto(media=uurl, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–æ—Ç–æ–≤—ã ‚úÖ"))
                else:
                    media.append(InputMediaPhoto(media=uurl))
            await cb.message.answer_media_group(media=media)
            # –í—Å–µ–≥–¥–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º + –∫–Ω–æ–ø–∫–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (—á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è–ª–æ—Å—å)
            await cb.message.answer(
                "–ì–æ—Ç–æ–≤–æ ‚úÖ\n–•–æ—á–µ—à—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –Ω–∞ DeviantArt? –ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ:",
                reply_markup=image_actions_kb()
            )

        elif main_url:
            await cb.message.answer_photo(photo=main_url, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ ‚úÖ", reply_markup=image_actions_kb())
        else:
            await cb.message.answer("–ì–æ—Ç–æ–≤–æ, –Ω–æ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω ü§î")

        try:
            await progress_msg.edit_text("–ì–æ—Ç–æ–≤–æ ‚úÖ")
        except TelegramBadRequest:
            pass
    finally:
        await cb.answer()



# ---------- –®–æ—Ä—Ç–∫–∞—Ç ----------
@router.callback_query(F.data.startswith("img:generate"))
async def img_generate_shortcut(cb: CallbackQuery, state: FSMContext):
    await state.update_data(
        selected_model_id=None,
        selected_model_name=None,
        selected_loras=[],
        loras_ready=False,
        image_count=1,
    )
    await cb.message.answer("–®–∞–≥ 1/4. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º–æ–¥–µ–ª—å</b>:", reply_markup=models_kb(MODELS, None))
    await cb.answer()

# ---------- –ù–∞–∑–∞–¥ –∫ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä—É/—Ä–µ–¥–∞–∫—Ç–æ—Ä—É ----------
async def _safe_show_editor(cb: CallbackQuery, text: str, gen_id: int):
    try:
        if cb.message and (cb.message.text is not None):
            await cb.answer(cache_time=1)
            await cb.message.edit_text(text, reply_markup=prompt_editor_kb(gen_id))
            return
    except TelegramBadRequest:
        pass
    await cb.answer(cache_time=1)
    await cb.message.answer(text, reply_markup=prompt_editor_kb(gen_id))

@router.callback_query(F.data == "back:editor")
async def back_editor(cb: CallbackQuery, state: FSMContext):
    u = await get_user(cb.from_user.id, cb.from_user.username)
    gen_id = await get_current_gen_id(state, u.id)
    if not gen_id:
        gen_id = await _ensure_generation_for_user(u.id, tg_user_id=cb.from_user.id)
        await set_current_gen(state, gen_id)
    async with async_session() as s:
        r = await s.execute(
            select(Generation).where(Generation.id == gen_id, Generation.user_id == u.id)
        )
        gen = r.scalar_one()
    llm_model = (await state.get_data()).get("last_llm_model")
    text = render_text_block_simple(gen, llm_model=llm_model)
    _json_set_active_gen_id_for_both(cb.from_user.id, u.id, gen_id)
    await _safe_show_editor(cb, text, gen_id)
